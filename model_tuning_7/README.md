dataset : 38000ê°œ ( 30400/ 3800/ 3800)

### ğŸ› ï¸ TrainingArguments ì„¤ì •í‘œ

| í•­ëª©             | ë³€ê²½ ì „ (v7) | ë³€ê²½ í›„ (v10) | ì„¤ëª…                                         |
| ---------------- | ------------ | ------------ | -------------------------------------------- |
| epoch (ë°˜ë³µíšŸìˆ˜) | 20            | 30          | ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•´ë´¤ìœ¼ë‚˜ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë–¨ì–´ì ¸ì„œ ê°€ì¥ ì¢‹ì•˜ë˜ ì„¸íŒ…ì—ì„œ ì—í­ì„ ëŠ˜ë¦¼ |
| lr (í•™ìŠµë¥ )    | 2e-4     | 1e-4 | ì—í­ì„ ëŠ˜ë¦¬ë©´ì„œ ë” ì²œì²œíˆ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ë„ë¡ ì„¤ì •     |

### code

```python
training_args = TrainingArguments(
    output_dir="./wav2vec2_finetune_ko_v10",
    eval_steps=500,
    save_steps=500,
    logging_steps=50,
    eval_strategy="steps",
    save_total_limit=3,
    num_train_epochs=30,
    per_device_train_batch_size=1,
    per_device_eval_batch_size=1,
    gradient_accumulation_steps=8,
    fp16=True,                             # AMP ì‚¬ìš©
    group_by_length=True,                  # ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ë°˜ ë™ì  ë°°ì¹˜ êµ¬ì„±
    weight_decay=0.005,
    learning_rate=1e-4,                    # ì‚´ì§ ë‚®ì¶¤
    warmup_ratio=0.05,
    dataloader_num_workers=4,
    report_to="none",                      # WandB ì•ˆ ì“¸ ë•Œ
)
```
## ê²°ê³¼

ì„±ëŠ¥ì€ ë™ì¼í•˜ì˜€ê³ , v7ë²„ì „ì„ ìµœì¢… ë²„ì „ìœ¼ë¡œ ì„ ì •